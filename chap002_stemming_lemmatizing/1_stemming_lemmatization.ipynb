{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9649f255-da32-4771-b13e-5cae5ce0bcd7",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Stemming and Lemmatization</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1649c632-d4fa-43e7-a653-e370f7ad9e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c44576-7289-4b38-ba18-0b89c412901a",
   "metadata": {},
   "source": [
    "### Definition of Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba42636-2c8e-49fd-9630-64c74fb714d9",
   "metadata": {},
   "source": [
    "Process of reducing inflected(or sometimes derived) words to their word stem or root.\n",
    "(or)\n",
    "Crudely chopping off the end of the word to leave only the base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4410a8e-7946-47d8-a387-c5e7a0c5ff6e",
   "metadata": {},
   "source": [
    "Examples of Stemmping:<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>id</th>\n",
    "        <th>Words</th>\n",
    "        <th>Stemming Word</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>Stemming/Stemmed</td>\n",
    "        <td>Stem</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>Electricity/Electrical</td>\n",
    "        <td>Elect</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>Berries/Berry</td>\n",
    "        <td>Berri</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>4</td>\n",
    "        <td>Meanness/Meaning</td>\n",
    "        <td>Mean</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d56d5-54ce-4c75-9ba3-e6ae72f61b28",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Stemming uses very crude rules, so it isn't perfect. In example 4 above both word are not closely releated but it come to conclusion of mean.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9f07a0-af08-4613-b197-bb986ecfd7c5",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Stemming helps to reduce the corpus of words. Below are different types of stemming methods available\n",
    "       <ol>\n",
    "           <li>Porter Stemmer</li>\n",
    "           <li>Snowball Stemmer</li>\n",
    "           <li>Lancaster Stemmer</li>\n",
    "           <li>Regex-Based Stemmer</li>\n",
    "       </ol>\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c5ec32-4acf-4543-bd74-d67e59ef38ce",
   "metadata": {},
   "source": [
    "### Demo of Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7e93d9-1e88-473c-beab-99f3457d2bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32cbf9cb-5fb5-40f2-886c-b3d09f807785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e4e55c-2dc3-4ab4-9a8c-4bea29671c84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grow\n",
      "grow\n",
      "grow\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem(\"grows\"))\n",
    "print(ps.stem(\"growing\"))\n",
    "print(ps.stem(\"grow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d16de705-3398-4b80-906a-36f548603e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "runner\n"
     ]
    }
   ],
   "source": [
    "# It is able to differential between noun and verbs\n",
    "print(ps.stem(\"run\"))\n",
    "print(ps.stem(\"running\"))\n",
    "print(ps.stem(\"runner\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fda08-8c57-432c-9202-11cf56e0cdb2",
   "metadata": {},
   "source": [
    "### Reading Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c887ec-d7b9-4f3f-a445-b07bf191120d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                          body_text\n",
       "0    ham  I've been searching for the right words to tha...\n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3    ham  Even my brother is not like to speak with me. ...\n",
       "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "nltk.data.path.append(r\"D:\\Artificial_Intelligence\\nat_lang_proc\\nltk_data\")\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "data_df = pd.read_csv(r\"D:/Artificial_Intelligence/nat_lang_proc/data/SMSSpamCollection.tsv\", delimiter=\"\\t\", header=None)\n",
    "data_df.columns = [\"labels\", \"body_text\"]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82b0425-cd52-4efd-b75f-1f0136dd8d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    without_punc = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    tokenzied_text = re.findall(\"\\w+\", without_punc)\n",
    "    text_nostopwords = [word for word in tokenzied_text if word not in stopwords]\n",
    "    return text_nostopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "448e1ba4-a4a4-42af-8501-a953ef7a0545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df[\"text_no_stopwords\"] = data_df[\"body_text\"].apply(lambda x:clean_data(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46899a5f-f650-4120-9f9c-559ef4192a80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                          body_text   \n",
       "0    ham  I've been searching for the right words to tha...  \\\n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3    ham  Even my brother is not like to speak with me. ...   \n",
       "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                   text_no_stopwords  \n",
       "0  [ive, searching, right, words, thank, breather...  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "2  [nah, dont, think, goes, usf, lives, around, t...  \n",
       "3  [even, brother, like, speak, treat, like, aids...  \n",
       "4                                     [date, sunday]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2647de1-c7ec-43c5-a068-df22e079da2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stemming Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b76f95f-9fc5-4e2e-bb48-9873bd9bbd09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stem_text(words_list):\n",
    "    text = [ps.stem(word) for word in words_list]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b40f86b-1c22-415e-9347-0c642e67c58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df[\"stem_words\"] = data_df[\"text_no_stopwords\"].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf30479a-b34c-4d38-97d0-c8c765bf0b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>stem_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "      <td>[ive, search, right, word, thank, breather, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                          body_text   \n",
       "0    ham  I've been searching for the right words to tha...  \\\n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3    ham  Even my brother is not like to speak with me. ...   \n",
       "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                   text_no_stopwords   \n",
       "0  [ive, searching, right, words, thank, breather...  \\\n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "2  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "3  [even, brother, like, speak, treat, like, aids...   \n",
       "4                                     [date, sunday]   \n",
       "\n",
       "                                          stem_words  \n",
       "0  [ive, search, right, word, thank, breather, pr...  \n",
       "1  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "2  [nah, dont, think, goe, usf, live, around, tho...  \n",
       "3  [even, brother, like, speak, treat, like, aid,...  \n",
       "4                                     [date, sunday]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264dbb0e-a54e-4ce6-9f2d-229f83532c6b",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3272f-c694-4620-b30c-86c52559891e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Lemmatization is a process of grouping together the inflected form of words so they can be analyzed as single term.\n",
    "The goal of lemmatization is to reduce a word to its root form, also called a lemma. Lemmatization links similar meaning words as one word, making tools such as chatbots and search engine queries more effective and accurate (or) Using vocabulary analysis of words aiming to remove inflectional endings to return the dictionary form of a word.\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39b812-31ed-4de4-a925-8dc3cde1fa2a",
   "metadata": {},
   "source": [
    "#### Stemming vs Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174bad3-34d3-4c5f-948d-ce6fa081fa9e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       <ul>\n",
    "            <li>The goal of both is to condense derived words in their base forms.</li>\n",
    "            <li>Stemming is typically faster as it is simply chops off the end of the word using heuristics, without any understanding of\n",
    "                the context in which a word is used</li>\n",
    "            <li>Lemmatization typically more accurate as it uses more informed analysis to create group of words with similar meaning based on the content around the word</li>\n",
    "        </ul>\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "264ea8ba-58d8-4978-9426-188339df4553",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaa09320-f651-4646-8b9b-06e975ccc7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'lemmatize']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(wn)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb5cd7dd-7d0a-4fac-804a-2aabfe9ac8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "mean\n"
     ]
    }
   ],
   "source": [
    "# Both words convey different meaning, but stemming treated them as 'mean'\n",
    "print(ps.stem(\"meanness\"))\n",
    "print(ps.stem(\"meaning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd92fb36-a708-4098-a114-bec6d4ed4679",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanness\n",
      "meaning\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization predicted correctly\n",
    "print(wn.lemmatize(\"meanness\"))\n",
    "print(wn.lemmatize(\"meaning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a82b732b-7f98-44b3-ba84-c3c2cebdddfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goos\n",
      "grees\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem(\"goose\"))\n",
    "print(ps.stem(\"greese\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1f4cf7b-48de-4629-a19b-ce662d9d2693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goose\n",
      "greese\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize(\"goose\"))\n",
    "print(wn.lemmatize(\"greese\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d2392-1962-43b2-8036-427be73c8df1",
   "metadata": {},
   "source": [
    "#### Applying lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8b73d6c-1641-42f0-86be-f3de9df29b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lemmatization(tokenized_text: List) -> List:\n",
    "    \"\"\"\n",
    "    :param tokenized_text: Tokens list\n",
    "    :type tokenized_text: List\n",
    "    :returns: A list of lemmatized tokens\n",
    "    :rtype: List\n",
    "    \"\"\"\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76dcb01b-0784-40b5-8600-6a265129cdba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text</th>\n",
       "      <th>text_no_stopwords</th>\n",
       "      <th>stem_words</th>\n",
       "      <th>lemmatized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "      <td>[ive, search, right, word, thank, breather, pr...</td>\n",
       "      <td>[ive, searching, right, word, thank, breather,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "      <td>[2nd, time, tri, 2, contact, u, u, 750, pound,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, go, esplanad, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>[pity, mood, soany, suggestions]</td>\n",
       "      <td>[piti, mood, soani, suggest]</td>\n",
       "      <td>[pity, mood, soany, suggestion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
       "      <td>[guy, bitch, act, like, id, interest, buy, som...</td>\n",
       "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                          body_text   \n",
       "0       ham  I've been searching for the right words to tha...  \\\n",
       "1      spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2       ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3       ham  Even my brother is not like to speak with me. ...   \n",
       "4       ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "...     ...                                                ...   \n",
       "5563   spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5564    ham               Will ü b going to esplanade fr home?   \n",
       "5565    ham  Pity, * was in mood for that. So...any other s...   \n",
       "5566    ham  The guy did some bitching but I acted like i'd...   \n",
       "5567    ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                      text_no_stopwords   \n",
       "0     [ive, searching, right, words, thank, breather...  \\\n",
       "1     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "2     [nah, dont, think, goes, usf, lives, around, t...   \n",
       "3     [even, brother, like, speak, treat, like, aids...   \n",
       "4                                        [date, sunday]   \n",
       "...                                                 ...   \n",
       "5563  [2nd, time, tried, 2, contact, u, u, 750, poun...   \n",
       "5564                 [ü, b, going, esplanade, fr, home]   \n",
       "5565                   [pity, mood, soany, suggestions]   \n",
       "5566  [guy, bitching, acted, like, id, interested, b...   \n",
       "5567                                 [rofl, true, name]   \n",
       "\n",
       "                                             stem_words   \n",
       "0     [ive, search, right, word, thank, breather, pr...  \\\n",
       "1     [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "2     [nah, dont, think, goe, usf, live, around, tho...   \n",
       "3     [even, brother, like, speak, treat, like, aid,...   \n",
       "4                                        [date, sunday]   \n",
       "...                                                 ...   \n",
       "5563  [2nd, time, tri, 2, contact, u, u, 750, pound,...   \n",
       "5564                     [ü, b, go, esplanad, fr, home]   \n",
       "5565                       [piti, mood, soani, suggest]   \n",
       "5566  [guy, bitch, act, like, id, interest, buy, som...   \n",
       "5567                                 [rofl, true, name]   \n",
       "\n",
       "                                       lemmatized_words  \n",
       "0     [ive, searching, right, word, thank, breather,...  \n",
       "1     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "2     [nah, dont, think, go, usf, life, around, though]  \n",
       "3     [even, brother, like, speak, treat, like, aid,...  \n",
       "4                                        [date, sunday]  \n",
       "...                                                 ...  \n",
       "5563  [2nd, time, tried, 2, contact, u, u, 750, poun...  \n",
       "5564                 [ü, b, going, esplanade, fr, home]  \n",
       "5565                    [pity, mood, soany, suggestion]  \n",
       "5566  [guy, bitching, acted, like, id, interested, b...  \n",
       "5567                                 [rofl, true, name]  \n",
       "\n",
       "[5568 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"lemmatized_words\"] = data_df[\"text_no_stopwords\"].apply(lemmatization)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645c5bd-f996-4f88-91d3-411045bae36a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
