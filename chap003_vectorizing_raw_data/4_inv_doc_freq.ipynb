{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3533f73-33c7-495d-a7f8-dd6e536ed8b9",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Term Frequency - Inverse Document Frequency(IF - IDF)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c2760b-ba43-44cd-ba2a-3c3758bfb5a8",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       TF-IDF creates a document term matrix, where there is one row per text message and the column represents a single unique term. But instead of cell representing the count, the cell represents a weighting that's mean to identify how important a word is to an invidual text message. The tf–idf value increases proportionally to the number of times a word appears in the document\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39c21f-524f-47a9-9e99-37a1297ae339",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$w_{ij} = tf_{ij} \\times log(\\frac{N}{df_{i}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa1d0d-08d9-487b-9bc8-3c25b8476264",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "      $tf_{ij}$: The number of times the term <i>i</i> occurs in text message <i>j</i> divided by total number of terms text message<br>\n",
    "$df_{i}$: Number of documents containing the term <i>i</i> <br>\n",
    "$N$: Total number of documents \n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182dec1-321f-4cf2-b5db-d1c1f6e7df66",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       <b>Calculation for example sentence</b>: I like NLP <br><br>\n",
    "       $tf_{NLP, j} = \\frac{Total\\hspace{0.1cm}num. \\hspace{0.1cm} of\\hspace{0.1cm}times\\hspace{0.1cm}NLP\\hspace{0.1cm}term\\hspace{0.1cm}occurred \\hspace{0.1cm}sentence}{Number\\hspace{0.1cm}of\\hspace{0.1cm}words\\hspace{0.1cm}in\\hspace{0.1cm}text\\hspace{0.1cm}message}$<br><br>\n",
    "       $tf_{NLP, j} = \\frac{1}{3} = 0.333$<br><br>\n",
    "       Lets assume number of message/documents in, $N=20$<br><br>\n",
    "       Total number of documents containing word NLP, $df_{NLP}=1$<br><br>\n",
    "       $w_{ij}=tf_{ij}\\times log(\\frac{N}{df_{i}}) = 0.333 \\times log(\\frac{20}{1}) = 0.333 \\times 1.301 =0.43$\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ba21c-a620-45d3-9efc-760b0c07ab79",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0fb10b-78af-4cec-9a40-13f62f627e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b0db8f-1b52-4fd7-8d00-33667e3946a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f1a5a5-6ef9-4afe-9a48-9e0a63367823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                          body_text\n",
       "0    ham  I've been searching for the right words to tha...\n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3    ham  Even my brother is not like to speak with me. ...\n",
       "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "nltk.data.path.append(r\"D:\\Artificial_Intelligence\\nat_lang_proc\\nltk_data\")\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "data_df = pd.read_csv(r\"D:/Artificial_Intelligence/nat_lang_proc/data/SMSSpamCollection.tsv\", delimiter=\"\\t\", header=None)\n",
    "data_df.columns = [\"labels\", \"body_text\"]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670177b-45a8-4192-8edd-168dee5da174",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432ea4e2-7481-4789-81d5-9fc614cc613c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    without_punc = \"\".join([char.lower() for char in text if char not in string.punctuation])\n",
    "    tokenzied_text = re.findall(\"\\w+\", without_punc)\n",
    "    stemmed_tokens = [ps.stem(word) for word in tokenzied_text if word not in stopwords]\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08955200-4693-40e0-ae78-533040ca1eb8",
   "metadata": {},
   "source": [
    "### IF-IDF Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf8e109-4f3d-4941-88a9-4089f8607442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 8106)\n",
      "['0' '008704050406' '0089mi' ... 'ü' 'üll' '〨ud']\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_data)\n",
    "X_tfidf = tfidf_vect.fit_transform(data_df[\"body_text\"])\n",
    "print(X_tfidf.shape)\n",
    "print(tfidf_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ba185-1099-421a-9044-8a984624dad2",
   "metadata": {},
   "source": [
    "#### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cb923e-3a2d-4b1b-b27c-4b3a101be491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sample = data_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc6d481-5874-4222-b51e-887de3ebcec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 201)\n",
      "['08002986030' '08452810075over18' '09061701461' '1' '100' '100000' '11'\n",
      " '12' '150pday' '16' '2' '20000' '2005' '21st' '3' '4' '4403ldnw1a7rw18'\n",
      " '4txtú120' '6day' '81010' '87077' '87121' '87575' '9' '900' 'aft' 'aid'\n",
      " 'alreadi' 'anymor' 'appli' 'ard' 'around' 'b' 'bless' 'breather'\n",
      " 'brother' 'call' 'caller' 'callertun' 'camera' 'cash' 'chanc' 'claim'\n",
      " 'click' 'co' 'code' 'colour' 'comin' 'comp' 'copi' 'cost' 'credit' 'cri'\n",
      " 'csh11' 'cup' 'custom' 'da' 'date' 'dont' 'eg' 'eh' 'england' 'enough'\n",
      " 'entitl' 'entri' 'even' 'fa' 'feel' 'final' 'fine' 'finish' 'first'\n",
      " 'free' 'friend' 'fulfil' 'go' 'goalsteam' 'goe' 'gonna' 'gota' 'grant'\n",
      " 'ha' 'help' 'hl' 'home' 'hour' 'httpwap' 'im' 'info' 'ive' 'jackpot'\n",
      " 'joke' 'k' 'kim' 'kl341' 'lar' 'latest' 'lccltd' 'like' 'link' 'live'\n",
      " 'lor' 'lunch' 'macedonia' 'make' 'may' 'mell' 'membership' 'messag'\n",
      " 'minnaminungint' 'miss' 'mobil' 'month' 'nah' 'name' 'nation' 'naughti'\n",
      " 'network' 'news' 'next' 'nurungu' 'oh' 'oru' 'patent' 'pay' 'per' 'pobox'\n",
      " 'poboxox36504w45wq' 'pound' 'press' 'prize' 'promis' 'questionstd' 'r'\n",
      " 'ratetc' 'receiv' 'receivea' 'rememb' 'repli' 'request' 'reward' 'right'\n",
      " 'scotland' 'search' 'select' 'send' 'serious' 'set' 'six' 'smth' 'soon'\n",
      " 'speak' 'spell' 'stock' 'str' 'stuff' 'sunday' 'take' 'talk' 'tc' 'team'\n",
      " 'text' 'thank' 'think' 'though' 'time' 'tkt' 'today' 'tonight' 'treat'\n",
      " 'tri' 'trywal' 'tsandc' 'txt' 'u' 'updat' 'ur' 'urgent' 'use' 'usf' 'v'\n",
      " 'valid' 'valu' 'vettam' 'want' 'wap' 'watch' 'way' 'week' 'wet' 'win'\n",
      " 'winner' 'wkli' 'wonder' 'wont' 'word' 'wwwdbuknet' 'xxxmobilemovieclub'\n",
      " 'xxxmobilemovieclubcomnqjkgighjjgcbl' 'ye' 'ü']\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect_sample = TfidfVectorizer(analyzer=clean_data)\n",
    "X_tfidf_sample = tfidf_vect_sample.fit_transform(data_sample[\"body_text\"])\n",
    "print(X_tfidf_sample.shape)\n",
    "print(tfidf_vect_sample.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ab1ee8-6205-4b16-9655-6ae2d8bd87ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>08002986030</th>\n",
       "      <th>08452810075over18</th>\n",
       "      <th>09061701461</th>\n",
       "      <th>1</th>\n",
       "      <th>100</th>\n",
       "      <th>100000</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>150pday</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>winner</th>\n",
       "      <th>wkli</th>\n",
       "      <th>wonder</th>\n",
       "      <th>wont</th>\n",
       "      <th>word</th>\n",
       "      <th>wwwdbuknet</th>\n",
       "      <th>xxxmobilemovieclub</th>\n",
       "      <th>xxxmobilemovieclubcomnqjkgighjjgcbl</th>\n",
       "      <th>ye</th>\n",
       "      <th>ü</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238737</td>\n",
       "      <td>0.238737</td>\n",
       "      <td>0.209853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   08002986030  08452810075over18  09061701461    1  100  100000   11   12   \n",
       "0          0.0           0.000000          0.0  0.0  0.0     0.0  0.0  0.0  \\\n",
       "1          0.0           0.198986          0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "2          0.0           0.000000          0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "3          0.0           0.000000          0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "4          0.0           0.000000          0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "\n",
       "   150pday   16  ...  winner      wkli    wonder      wont      word   \n",
       "0      0.0  0.0  ...     0.0  0.000000  0.238737  0.238737  0.209853  \\\n",
       "1      0.0  0.0  ...     0.0  0.198986  0.000000  0.000000  0.000000   \n",
       "2      0.0  0.0  ...     0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.0  0.0  ...     0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.0  0.0  ...     0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   wwwdbuknet  xxxmobilemovieclub  xxxmobilemovieclubcomnqjkgighjjgcbl   ye   \n",
       "0         0.0                 0.0                                  0.0  0.0  \\\n",
       "1         0.0                 0.0                                  0.0  0.0   \n",
       "2         0.0                 0.0                                  0.0  0.0   \n",
       "3         0.0                 0.0                                  0.0  0.0   \n",
       "4         0.0                 0.0                                  0.0  0.0   \n",
       "\n",
       "     ü  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_df = pd.DataFrame(X_tfidf_sample.toarray())\n",
    "sample_data_df.columns = tfidf_vect_sample.get_feature_names_out()\n",
    "sample_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd1f62-aab5-45cd-9343-2c3a6a7e6277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
