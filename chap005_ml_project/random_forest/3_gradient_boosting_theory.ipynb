{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e620a738-e6d1-4eb7-b7f6-83a0b81d9fa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Gradient Boosting</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1489308-9aff-4658-8c33-85cc79daf22e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Gradient Boosting is an ensemble method that takes an iterative approch to combine weak learners to create\n",
    "       a stronger learner by focusing on the mistakes of the previous iterations. Gradient Boosting also uses decision\n",
    "       trees but they are incredibly basic. Gradient Boosting model evaluates what it gets right and what it gets wrong\n",
    "       on that first tree, and then with the next iteration it places a heavier weight on those observations that it got\n",
    "       wrong and it does this over and over again focusing on the examples it doesn't quite understand yet until\n",
    "       it has minimized the error as much as possible.\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012eea8-8f8f-43dc-ac79-2233fbc06dba",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Gradient Boosting model trees can't be parallelized like Random Forest trees due to its dependency on the previous decision tree result.\n",
    "       So training process of Gradient Boosting is slow when compared with Random Forest.\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9502b64f-28f8-4be7-84f1-c6c4dc3804b8",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Pro of Gradient Boosting:\n",
    "       <ul>\n",
    "           <li> It is extremely powerful </li>\n",
    "           <li> Accepts various types of inputs</li>\n",
    "           <li> Can be used for both classification and regression</li>\n",
    "           <li> Ouput feature importance </li>\n",
    "       </ul>\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9570ab0-e33b-43e0-8a5d-3f79926d9cab",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Cons of Gradient Boosting:\n",
    "       <ul>\n",
    "           <li>Longer to train (can't parallelized)</li>\n",
    "           <li>More likely overfit</li>\n",
    "           <li>More difficultto properly tune</li>\n",
    "       </ul>\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0f182-97f2-411a-bd12-d44d03330a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
