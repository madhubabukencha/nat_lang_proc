{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54a37a8-3f79-49b6-aa11-ed937739b955",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Doc2Vec</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620aeab1-9b9c-4b58-908d-85ed43836a35",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "    <font size=3>\n",
    "        Doc2Vec is a shallow, two-layer neural network that accepts a text corpus as an input,\n",
    "        and it returns a set of vectors(also known as embeddings); each vector is a numeric representation\n",
    "        of a given sentence, paragraph or document.\n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deefb43-516e-46b7-b6c0-ecf4230b26dc",
   "metadata": {},
   "source": [
    "### Importing Required Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3fea12-eb26-4264-961a-87d7c7c8ff9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82cd0f-55e3-4f2e-a3f2-9ad7639277f0",
   "metadata": {},
   "source": [
    "### Cleaning and Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728450f9-3f21-45dc-9ca2-d346c1b0573f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>jurong point, crazy.. available bugis n great ...</td>\n",
       "      <td>[jurong, point, crazy, available, bugis, great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun early hor... u c say...</td>\n",
       "      <td>[dun, early, hor, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah don't think goes usf, lives</td>\n",
       "      <td>[nah, don, think, goes, usf, lives]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text   \n",
       "0   ham  jurong point, crazy.. available bugis n great ...  \\\n",
       "1   ham                      ok lar... joking wif u oni...   \n",
       "2  spam  free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3   ham                      u dun early hor... u c say...   \n",
       "4   ham                    nah don't think goes usf, lives   \n",
       "\n",
       "                                          text_clean  \n",
       "0  [jurong, point, crazy, available, bugis, great...  \n",
       "1                        [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3                             [dun, early, hor, say]  \n",
       "4                [nah, don, think, goes, usf, lives]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This process is similar to wor2vec\n",
    "messages_df = pd.read_csv(\"data/spam.csv\", encoding=\"latin-1\")\n",
    "messages_df = messages_df.drop(labels=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "messages_df.columns = [\"label\", \"text\"]\n",
    "messages_df[\"text\"] = messages_df[\"text\"].apply(lambda x: gensim.parsing.preprocessing.remove_stopwords(x.lower()))\n",
    "messages_df[\"text_clean\"] = messages_df[\"text\"].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cf100c-d82e-4db8-847e-5297cb2bb5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages_df[\"text_clean\"], \n",
    "                                                    messages_df[\"label\"],\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d236e2-0a53-4f5e-9601-b58cbee8bdee",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "    <font size=3>\n",
    "        One of the difference between wor2vec and doc2vec is, doc2vec requires you to create a tagged for each document.\n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9eb1117-a0fb-4034-9f89-6283f5281f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tagged_docs = [gensim.models.doc2vec.TaggedDocument(message, [tag])\n",
    "               for tag, message in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d277135b-9d2b-4562-bb9c-293cc366e843",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['Ã¬_', 'send', 'copy', 'da', 'report'], tags=[0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how tagged document looks like\n",
    "tagged_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "645c894e-1d33-4caf-bd6d-becc38ce1fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a basic doc2vec model\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs,\n",
    "                                  vector_size=100,\n",
    "                                  window=5,\n",
    "                                  min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9a218c4-45a6-4edc-a190-4b1d6d8c0c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter doc_words of infer_vector() must be a list of strings (not a single string).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# if pass a single string to see a vector it will through an error\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43md2v_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Artificial_Intelligence\\ai_ml_venv\\Lib\\site-packages\\gensim\\models\\doc2vec.py:622\u001b[0m, in \u001b[0;36mDoc2Vec.infer_vector\u001b[1;34m(self, doc_words, alpha, min_alpha, epochs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Infer a vector for given post-bulk training document.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03mNotes\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    619\u001b[0m \n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_words, \u001b[38;5;28mstr\u001b[39m):  \u001b[38;5;66;03m# a common mistake; fail with a nicer error\u001b[39;00m\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter doc_words of infer_vector() must be a list of strings (not a single string).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    624\u001b[0m alpha \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\n\u001b[0;32m    625\u001b[0m min_alpha \u001b[38;5;241m=\u001b[39m min_alpha \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha\n",
      "\u001b[1;31mTypeError\u001b[0m: Parameter doc_words of infer_vector() must be a list of strings (not a single string)."
     ]
    }
   ],
   "source": [
    "# if pass a single string to see a vector it will through an error\n",
    "d2v_model.infer_vector(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e53449bc-3bbf-4f5d-9e23-0588d7b292d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01670334,  0.01506151,  0.01069222, -0.00099723,  0.01174583,\n",
       "       -0.02641355,  0.01006052,  0.03633425, -0.00801944, -0.01884378,\n",
       "       -0.01059441, -0.03392114,  0.0077312 ,  0.00724932,  0.00435393,\n",
       "       -0.01755195, -0.00129795, -0.03394359,  0.00842868, -0.0376656 ,\n",
       "        0.02096071,  0.01253987,  0.01408338, -0.0073376 , -0.00260323,\n",
       "        0.00035145, -0.013527  , -0.01244347, -0.01531816,  0.00457848,\n",
       "        0.02517725,  0.00314163,  0.00578883, -0.00276743, -0.0051368 ,\n",
       "        0.02993125, -0.0006773 , -0.00904137, -0.00885883, -0.03443177,\n",
       "        0.00085865, -0.02342424, -0.00166096,  0.00544285,  0.01690786,\n",
       "       -0.00842708, -0.00368595, -0.00519634,  0.00580165,  0.01186061,\n",
       "        0.01635859, -0.00939585, -0.00151957, -0.00035397, -0.02264286,\n",
       "        0.00785382,  0.01268574, -0.00524943, -0.01497518,  0.01326055,\n",
       "        0.01511205,  0.00219207, -0.0104853 ,  0.00257377, -0.0219974 ,\n",
       "        0.02341004,  0.00325897, -0.00109748, -0.02742057,  0.02105737,\n",
       "       -0.0138494 ,  0.01961433,  0.02626325, -0.00712304,  0.02255975,\n",
       "        0.01278904, -0.01106485, -0.00329453, -0.01285428,  0.00756138,\n",
       "       -0.01182541, -0.00691316, -0.00999468,  0.01883183, -0.00091268,\n",
       "        0.00777442, -0.00216971,  0.01636791,  0.02599926,  0.01665368,\n",
       "        0.02316646,  0.01314714, -0.00487714,  0.01299499,  0.03043602,\n",
       "        0.01394133,  0.00738855, -0.02141575,  0.0017328 ,  0.00200239],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below line might be in the text messages but still it able to generate a vector.\n",
    "d2v_model.infer_vector([\"i\", \"am\", \"learning\", \"nlp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "724ac4f1-7515-4c15-a6fe-a2f1d6262c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing data for machine learning model\n",
    "vectors = [[d2v_model.infer_vector(words)] for words in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36c5436a-6d90-410f-a807-272b7fa593bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01600209,  0.01305018,  0.00265853, -0.00142869,  0.00875799,\n",
       "        -0.02439217,  0.00783628,  0.02846464, -0.01510691, -0.00980889,\n",
       "        -0.00184414, -0.02052439,  0.00045317,  0.01417863,  0.00763485,\n",
       "        -0.00900592, -0.00113399, -0.02850657,  0.00791143, -0.02818114,\n",
       "         0.00818712,  0.00916575,  0.01372023, -0.00880946, -0.00138504,\n",
       "         0.00513204, -0.02041306, -0.0066932 , -0.01267459,  0.00080392,\n",
       "         0.01497518, -0.00087495,  0.00384755, -0.00099499, -0.00689779,\n",
       "         0.02301539, -0.0040477 , -0.00924474, -0.00441097, -0.03417779,\n",
       "        -0.00123487, -0.0154581 , -0.00444547, -0.00095956,  0.01552329,\n",
       "        -0.010543  , -0.00792183, -0.00501963,  0.01103252,  0.0084653 ,\n",
       "         0.00677812, -0.00182994, -0.00559629, -0.00368985, -0.01173695,\n",
       "        -0.00034725,  0.00565822, -0.00479573, -0.0108868 ,  0.00696854,\n",
       "         0.00535064,  0.00439968, -0.00579093, -0.00245765, -0.02306881,\n",
       "         0.01168393,  0.00489581,  0.00114061, -0.01834535,  0.02099188,\n",
       "        -0.00963602,  0.01587992,  0.02138159, -0.00614968,  0.01756815,\n",
       "         0.00525901, -0.01132756, -0.00024953, -0.00883579,  0.00771976,\n",
       "        -0.01490592, -0.0029545 , -0.00632158,  0.02106141, -0.00551626,\n",
       "         0.0059528 ,  0.00308651,  0.01778216,  0.01941806,  0.00846515,\n",
       "         0.01953545,  0.00967099,  0.00101613,  0.01238765,  0.02565529,\n",
       "         0.01886307,  0.00913601, -0.02402733,  0.00283283, -0.0009518 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912c2cc-e0e5-461e-87d9-dc480263c2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
