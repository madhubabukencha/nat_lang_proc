{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0618a7-4e24-421a-b953-84b7cf6cce0d",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Model Selection</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef9803-0a2d-4537-a7fd-32afbaefb998",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       In this notebook, we will compare multiple embedding technics and we will select one\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7730d6-7791-407b-957a-832cfbe1c889",
   "metadata": {},
   "source": [
    "### Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240a9866-b4b0-4cfc-ad0e-7f28b7dee2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a76927-57fc-4715-8319-147571f511ee",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ecf7193-0902-4224-b0ac-d587160b7296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.data.path.append(r\"D:\\Artificial_Intelligence\\nat_lang_proc\\nltk_data\")\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "data_df = pd.read_csv(r\"D:\\Artificial_Intelligence\\nat_lang_proc\\data\\spam.csv\", \n",
    "                          encoding=\"latin-1\")\n",
    "data_df = data_df.drop(labels=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "data_df.columns = [\"label\", \"text\"]\n",
    "labels = np.where(data_df[\"label\"] == \"spam\", 1, 0)\n",
    "\n",
    "def clean_data(text):\n",
    "    without_punc = \"\".join([char.lower() for char in text if char not in string.punctuation])\n",
    "    tokenzied_text = re.findall(\"\\w+\", without_punc)\n",
    "    stemmed_tokens = [word for word in tokenzied_text if word not in stopwords]\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb1e9a2-9084-4c39-9fff-887afa6ff58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df[\"clean_text\"] = data_df[\"text\"].apply(lambda x: clean_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d46bd0-b57a-44aa-a79d-855602d06b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text   \n",
       "0   ham  Go until jurong point, crazy.. Available only ...  \\\n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc51888c-a89a-4fe9-9c0b-c24778a225fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_df[\"clean_text\"],\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2624c112-429c-4cd3-8323-839ef420291d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'bugis',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c8fdf5-39d2-4aa9-b9cd-71a20c4405c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing data to files to use it in other chapters\n",
    "X_train.to_csv(\"data/X_train.csv\", index=False, header=True)\n",
    "X_test.to_csv(\"data/X_test.csv\", index=False, header=True)\n",
    "# While writing to a file list type changing to object. It is causing errors in Word2Vec\n",
    "X_train.to_pickle(\"data/X_train.pkl\")\n",
    "X_test.to_pickle(\"data/X_test.pkl\")\n",
    "pd.DataFrame(y_train, columns=[\"labels\"]).to_csv(\"data/y_train.csv\",\n",
    "                                              index=False,\n",
    "                                              header=True)\n",
    "pd.DataFrame(y_test, columns=[\"labels\"]).to_csv(\"data/y_test.csv\",\n",
    "                                              index=False,\n",
    "                                              header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3e576-d33f-40a8-a217-7fdadeec2706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
